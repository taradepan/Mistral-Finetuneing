{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -q -U transformers datasets accelerate peft trl bitsandbytes wandb"]},{"cell_type":"raw","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["import os\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    pipeline,\n",")\n","\n","from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n","from trl import SFTTrainer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    pipeline,\n",")\n","\n","from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n","from trl import SFTTrainer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["base_model = \"mistralai/Mistral-7B-v0.1\"\n","new_model = \"mistral-dolly\"\n","\n","dataset = load_dataset(\"taradepan/Dolly-preprocessed\", split=\"train\")\n","tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type='nf4',\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_use_double_quant=True,\n",")\n","\n","peft_config = LoraConfig(\n","    lora_alpha=32,\n","    lora_dropout=0.05,\n","    r=16,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=['up_proj', 'down_proj','gate_proj', 'k_proj','q_proj', 'v_proj','o_proj']\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    quantization_config=bnb_config,\n","    device_map={\"\": 0},\n",")\n","\n","model = prepare_model_for_kbit_training(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_arguments = TrainingArguments(\n","    output_dir=\"./results\",\n","    num_train_epochs=4,\n","    per_device_train_batch_size=10,\n","    gradient_accumulation_steps=1,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=1000,\n","    logging_steps=1,\n","    optim=\"paged_adamw_8bit\",\n","    learning_rate=2e-4,\n","    lr_scheduler_type=\"linear\",\n","    warmup_steps=10,\n","    report_to=\"wandb\",\n",")\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset,\n","    eval_dataset=dataset,\n","    peft_config=peft_config,\n","    dataset_text_field=\"input\",\n","    max_seq_length=300,\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n",")\n","trainer.train()\n","trainer.model.save_pretrained(new_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["prompt = \"what is a large language model?\"\n","input = f\"### Input: {prompt}\\n\\n Response:\\n\"\n","pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n","result = pipe(input) \n","print(result[0][\"generated_text\"][len(input):])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["del model\n","del pipe\n","del trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    low_cpu_mem_usage=True,\n","    return_dict=True,\n","    torch_dtype=torch.float16,\n","    device_map={\"\": 0},\n",")\n","model = PeftModel.from_pretrained(model, new_model)\n","model = model.merge_and_unload()\n","\n","tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token+0\n","tokenizer.padding_side = 'right'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.push_to_hub(new_model, use_temp_dir=False, token=hf_token)\n","tokenizer.push_to_hub(new_model, use_temp_dir=False, token=hf_token)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4174943,"sourceId":7214678,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":3900,"sourceId":5112,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
